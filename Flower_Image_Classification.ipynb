{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kxv8nx4kk_0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cigY0YyYkyQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flower Image Classification"
      ],
      "metadata": {
        "id": "Cy1gSZJCk9v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libararies\n",
        "from google.colab import drive #for mounting Google drive\n",
        "import os #for interacting with files\n",
        "import matplotlib.pyplot as plt # for plotting images and results\n",
        "import numpy as np # for numeric operations\n",
        "import cv2 #for image processing\n",
        "from sklearn.model_selection import train_test_split #for splitting data\n",
        "from PIL import Image # for manipulating images\n",
        "import shutil\n",
        "\n",
        "#augmentation libraray\n",
        "import albumentations as A # for image augmentaion\n",
        "from albumentations.augmentations.transforms import *\n",
        "from albumentations.pytorch import ToTensorV2 #to convert image into tensor format for Pytorch\n",
        "from tqdm import tqdm\n",
        "\n",
        "#model related imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.applications import DenseNet121"
      ],
      "metadata": {
        "id": "-jm0RfckkySo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "BEbg9N3ElElV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset from drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yxNULFPjkyUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define global variables\n",
        "img_size = 240\n",
        "data_path = '/content/drive/MyDrive/Flower_dataset/train'\n",
        "categories = ['daisy','dandelion','rose','sunflower','tulip']"
      ],
      "metadata": {
        "id": "_mObnwQpkyXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define function to count images in each category\n",
        "def count_images(directory):\n",
        "  for category in categories:\n",
        "    path = os.path.join(directory, category) #construct path\n",
        "    images = os.listdir(path) #name of all images present\n",
        "    print(f'{category} : {len(images)} images')\n",
        "count_images(data_path)"
      ],
      "metadata": {
        "id": "MpdE6NpTkyZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize data\n",
        "for category in categories:\n",
        "  path = os.path.join(data_path, category)\n",
        "  images = os.listdir(path)\n",
        "\n",
        "  fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
        "  fig.suptitle(f'{category}' , fontsize = 18)\n",
        "\n",
        "  for i in range(3): #plot first three images\n",
        "    img_name = images[np.random.randint(0, len(images))]\n",
        "    img_path = os.path.join(path, img_name)\n",
        "    img_array = cv2.imread(img_path)\n",
        "\n",
        "    #converting the BGR images to RGB\n",
        "    img_rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    ax[i].imshow(img_rgb)\n",
        "    ax[i].axis('off')"
      ],
      "metadata": {
        "id": "PcQqmZd4kybf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "iyv_V2AtlQ89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize data\n",
        "for category in categories:\n",
        "  path = os.path.join(data_path, category)\n",
        "  images = os.listdir(path)\n",
        "\n",
        "  fig, ax = plt.subplots(1, 3, figsize=(15, 3))\n",
        "  fig.suptitle(f'{category}' , fontsize = 18)\n",
        "\n",
        "  for i in range(3): #plot first three images\n",
        "    img_name = images[np.random.randint(0, len(images))]\n",
        "    img_path = os.path.join(path, img_name)\n",
        "    img_array = cv2.imread(img_path)\n",
        "\n",
        "    #converting the BGR images to RGB\n",
        "    img_rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    ax[i].imshow(img_rgb)\n",
        "    ax[i].axis('off')"
      ],
      "metadata": {
        "id": "49pL0kjbkydu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into train validation and test"
      ],
      "metadata": {
        "id": "PwFfvbOwkygF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/split_data'  # New folder to store split data"
      ],
      "metadata": {
        "id": "o3njZf3_kyiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train/val/test directories\n",
        "for split in ['train', 'val', 'test']:\n",
        "    for category in categories:\n",
        "        os.makedirs(os.path.join(base_dir, split, category), exist_ok=True)"
      ],
      "metadata": {
        "id": "Xui8TOM5kyke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split each category\n",
        "for category in categories:\n",
        "    img_dir = os.path.join(data_path, category)\n",
        "    images = os.listdir(img_dir)\n",
        "    train_val, test = train_test_split(images, test_size=0.15, random_state=42)\n",
        "    train, val = train_test_split(train_val, test_size=0.176, random_state=42)  # 0.176 x 85% â‰ˆ 15%\n",
        "\n",
        "    for split, split_data in zip(['train', 'val', 'test'], [train, val, test]):\n",
        "        for img_name in split_data:\n",
        "            src = os.path.join(img_dir, img_name)\n",
        "            dst = os.path.join(base_dir, split, category, img_name)\n",
        "            shutil.copy2(src, dst)"
      ],
      "metadata": {
        "id": "Z6bRGWfhkyn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check number of images in each folder\n",
        "splits = ['train', 'val', 'test']\n",
        "for split in splits:\n",
        "    print(f\"\\n{split.upper()} DATA:\")\n",
        "    for category in categories:\n",
        "        folder_path = os.path.join(base_dir, split, category)\n",
        "        num_images = len(os.listdir(folder_path))\n",
        "        print(f\"  {category} : {num_images} images\")"
      ],
      "metadata": {
        "id": "E38VPy77lbgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmenttaion on train data only"
      ],
      "metadata": {
        "id": "HewYMRLklbiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define augmentation pipeline\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.Rotate(limit=25, p=0.7),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Resize(img_size, img_size),  # Ensure size remains compatible\n",
        "])\n",
        "\n",
        "# Set data directory and categories\n",
        "data_dir = '/content/split_data/train'  # folder path\n",
        "categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ],
      "metadata": {
        "id": "JbD1HvWalbji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to augment and save images\n",
        "def augment_and_save_images(data_dir, categories, transform, num_augments=1):\n",
        "    for category in categories:\n",
        "        path = os.path.join(data_dir, category)\n",
        "        for filename in tqdm(os.listdir(path), desc=f'Augmenting {category}'):\n",
        "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_path = os.path.join(path, filename)\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is None:\n",
        "                    continue\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                for i in range(num_augments):\n",
        "                    augmented = transform(image=image)\n",
        "                    augmented_image = augmented['image']\n",
        "                    aug_filename = f\"{os.path.splitext(filename)[0]}_aug{i}.jpg\"\n",
        "                    save_path = os.path.join(path, aug_filename)\n",
        "                    cv2.imwrite(save_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))"
      ],
      "metadata": {
        "id": "IcolM_AWlbnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the augmentation\n",
        "augment_and_save_images(data_dir, categories, transform, num_augments=1)"
      ],
      "metadata": {
        "id": "3La50Syulh8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check number of images after augmenatation\n",
        "base_path = '/content/split_data'  #base directory\n",
        "\n",
        "splits = ['train', 'val', 'test']\n",
        "categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
        "\n",
        "for split in splits:\n",
        "    print(f\"\\n{split.upper()} DATA:\")\n",
        "    for category in categories:\n",
        "        folder_path = os.path.join(base_path, split, category)\n",
        "        num_images = len(os.listdir(folder_path))\n",
        "        print(f\"  {category} : {num_images} images\")"
      ],
      "metadata": {
        "id": "sCb7H401lh_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image data need to be converted into ndarray with proper label"
      ],
      "metadata": {
        "id": "DADHjs01liCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "IMG_SIZE = 240\n",
        "categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
        "DATADIR_TRAIN = '/content/split_data/train'\n",
        "DATADIR_VAL = '/content/split_data/val'\n",
        "DATADIR_TEST = '/content/split_data/test'\n",
        "\n",
        "# Function to load data\n",
        "def load_data(DATADIR):\n",
        "    data = []  # Will hold image arrays and labels\n",
        "    for category in categories:\n",
        "        path = os.path.join(DATADIR, category)  # Path to category folder\n",
        "        label = categories.index(category)  # Label as index\n",
        "        for img_name in os.listdir(path):  # Loop over images in category folder\n",
        "            try:\n",
        "                img_path = os.path.join(path, img_name)\n",
        "                img_array = cv2.imread(img_path)  # Load image\n",
        "                img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "                img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # Resize image\n",
        "                data.append([img_array, label])  # Append image and label\n",
        "            except Exception as e:\n",
        "                pass  # If an error occurs, skip this image\n",
        "    return data\n",
        "\n",
        "# Load training, validation, and test data\n",
        "train_data = load_data(DATADIR_TRAIN)\n",
        "val_data = load_data(DATADIR_VAL)\n",
        "test_data = load_data(DATADIR_TEST)\n"
      ],
      "metadata": {
        "id": "ZL9Hmu5uliGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels\n",
        "X_train = np.array([item[0] for item in train_data])\n",
        "y_train = np.array([item[1] for item in train_data])\n",
        "\n",
        "X_val = np.array([item[0] for item in val_data])\n",
        "y_val = np.array([item[1] for item in val_data])\n",
        "\n",
        "X_test = np.array([item[0] for item in test_data])\n",
        "y_test = np.array([item[1] for item in test_data])"
      ],
      "metadata": {
        "id": "DLbWY8hNlqUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape X to the correct input shape for CNNs\n",
        "X_train = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "X_val = X_val.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "X_test = X_test.reshape(-1, IMG_SIZE, IMG_SIZE, 3)"
      ],
      "metadata": {
        "id": "XF6_RUT0lqWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalization\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_val = X_val.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n"
      ],
      "metadata": {
        "id": "wFRJeEr_lthA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get total number of images in the training set\n",
        "total_train_images = X_train.shape[0]\n",
        "print(f'Total number of training images: {total_train_images}')\n"
      ],
      "metadata": {
        "id": "DU4C-L4xltjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model building"
      ],
      "metadata": {
        "id": "Rb3C5hoHlxoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load DenseNet121 base model\n",
        "base_model = tf.keras.applications.DenseNet121(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(240, 240, 3)\n",
        ")\n",
        "\n",
        "# Step 2: Freeze the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Step 3: Build your model with Dropout\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Dense(1024, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Step 4: Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "H4-PgKaGltld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NEvRsX7Lltow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), batch_size=32)"
      ],
      "metadata": {
        "id": "zBT4vPxel6C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Predict class probabilities or labels on the validation set\n",
        "y_pred_probs = model.predict(X_val)\n",
        "\n",
        "# 2.\n",
        "\n",
        "# Binary classification\n",
        "if y_pred_probs.shape[1] == 1:\n",
        "    y_pred = (y_pred_probs > 0.5).astype(\"int32\")\n",
        "else:\n",
        "    # Multi-class classification\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# 3. Ensure y_val is in correct form\n",
        "if y_val.ndim > 1 and y_val.shape[1] > 1:\n",
        "    y_true = np.argmax(y_val, axis=1)\n",
        "else:\n",
        "    y_true = y_val\n",
        "\n",
        "# 4. Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QxhREjCFl6FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"flower_classifier_model.keras\")"
      ],
      "metadata": {
        "id": "J7xZ149tl9yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 1. Predictions\n",
        "y_train_pred_probs = model.predict(X_train)\n",
        "y_val_pred_probs = model.predict(X_val)\n",
        "\n",
        "# 2. Convert probabilities to class labels\n",
        "y_train_pred = np.argmax(y_train_pred_probs, axis=1)\n",
        "y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
        "\n",
        "# 3. Ground truth (already in integer format)\n",
        "y_train_true = y_train\n",
        "y_val_true = y_val\n",
        "\n",
        "# 4. Compute metrics\n",
        "def print_metrics(y_true, y_pred, dataset_name):\n",
        "    print(f\"\\nðŸ“Š Metrics for {dataset_name} Set:\")\n",
        "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_true, y_pred, average='macro'))\n",
        "    print(\"Recall   :\", recall_score(y_true, y_pred, average='macro'))\n",
        "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='macro'))\n",
        "\n",
        "print_metrics(y_train_true, y_train_pred, \"Train\")\n",
        "print_metrics(y_val_true, y_val_pred, \"Validation/Test\")\n"
      ],
      "metadata": {
        "id": "Q4GIULnEl90o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('accuracy_plot.png', dpi=300)  # Save the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3r5Ti-6Vl929"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('loss_plot.png', dpi=300)  # Save the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H6ZHsVB3l96j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check on unseen data"
      ],
      "metadata": {
        "id": "zqEQ6HwAl6Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"flower_classifier_model.keras\")\n"
      ],
      "metadata": {
        "id": "CxRyeNSFlqaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess image\n",
        "img_path = '/content/split_data/test/sunflower/12471443383_b71e7a7480_m.jpg'  # change this to your actual image path\n",
        "img = image.load_img(img_path, target_size=(240, 240))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array = preprocess_input(img_array)        # Preprocessing for DenseNet\n"
      ],
      "metadata": {
        "id": "euqjTdMsmJFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ],
      "metadata": {
        "id": "LrLiKLLZmJHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(img_array)\n",
        "predicted_class = np.argmax(pred, axis=1)[0]\n",
        "print(\"Predicted class:\", class_names[predicted_class])"
      ],
      "metadata": {
        "id": "L7gITsdjmJKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oHCv8dXmmJND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NwYZpdnxmJQg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}